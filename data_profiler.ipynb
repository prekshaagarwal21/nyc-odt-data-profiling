{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f3c82f-fc50-4aa1-adb2-60aad11b61ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/ubuntu/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas_profiling in /opt/conda/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: matplotlib>=3.2.0 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (3.3.3)\n",
      "Requirement already satisfied: markupsafe~=2.0.1 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (2.0.1)\n",
      "Requirement already satisfied: visions[type_image_path]==0.7.4 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (0.7.4)\n",
      "Requirement already satisfied: missingno>=0.4.2 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (0.5.1)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (1.2.0)\n",
      "Requirement already satisfied: tangled-up-in-unicode==0.1.0 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (0.1.0)\n",
      "Requirement already satisfied: joblib~=1.0.1 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (1.0.1)\n",
      "Requirement already satisfied: phik>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (0.12.2)\n",
      "Requirement already satisfied: requests>=2.24.0 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (2.25.1)\n",
      "Requirement already satisfied: multimethod>=1.4 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (1.8)\n",
      "Requirement already satisfied: seaborn>=0.10.1 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (0.11.1)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (3.0.3)\n",
      "Requirement already satisfied: htmlmin>=0.1.12 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (0.1.12)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (4.55.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (1.6.0)\n",
      "Requirement already satisfied: pydantic>=1.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (1.9.1)\n",
      "Requirement already satisfied: PyYAML>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from pandas_profiling) (5.4.1)\n",
      "Requirement already satisfied: networkx>=2.4 in /opt/conda/lib/python3.8/site-packages (from visions[type_image_path]==0.7.4->pandas_profiling) (2.8.1)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /opt/conda/lib/python3.8/site-packages (from visions[type_image_path]==0.7.4->pandas_profiling) (21.4.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.8/site-packages (from visions[type_image_path]==0.7.4->pandas_profiling) (8.1.0)\n",
      "Requirement already satisfied: imagehash in /opt/conda/lib/python3.8/site-packages (from visions[type_image_path]==0.7.4->pandas_profiling) (4.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.0->pandas_profiling) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.0->pandas_profiling) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.0->pandas_profiling) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.0->pandas_profiling) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas_profiling) (2021.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from pydantic>=1.8.1->pandas_profiling) (4.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.24.0->pandas_profiling) (2022.5.18.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.24.0->pandas_profiling) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.24.0->pandas_profiling) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.24.0->pandas_profiling) (1.26.9)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=3.2.0->pandas_profiling) (1.15.0)\n",
      "Requirement already satisfied: PyWavelets in /opt/conda/lib/python3.8/site-packages (from imagehash->visions[type_image_path]==0.7.4->pandas_profiling) (1.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!sudo pip install pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0fe43a7-8b21-4b1f-bcf9-ded8678e8812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/ubuntu/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: gspread in /opt/conda/lib/python3.8/site-packages (5.4.0)\n",
      "Requirement already satisfied: google-auth>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from gspread) (1.25.0)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from gspread) (0.4.2)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.12.0->gspread) (62.3.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.12.0->gspread) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.12.0->gspread) (4.7)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.12.0->gspread) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.12.0->gspread) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.4.8)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.25.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.1.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (1.26.9)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.0.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!sudo pip install gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c2c2ff-5402-45bb-904b-5d9750b301f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "import numpy as np\n",
    "import string\n",
    "from google.oauth2 import service_account\n",
    "import gspread\n",
    "\n",
    "from pathlib import Path\n",
    "import os \n",
    "\n",
    "import time, datetime, os\n",
    "import shutil \n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dff522f-b8c6-4f53-b777-fd1d119eeddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check today's date and create a directory file structure for today's date.\n",
    "today = datetime.date.today()  \n",
    "todaystr = today.isoformat()   \n",
    "\n",
    "def create_date_dir():\n",
    "    i = 0\n",
    "    d = todaystr\n",
    "    if not os.path.exists(d):\n",
    "        os.mkdir(d)\n",
    "    else:\n",
    "        '''#if os.path.exists(d):\n",
    "        #    i += 1\n",
    "        #    d = d[:10] + '_' + str(i).zfill(2)\n",
    "        #os.mkdir(d)\n",
    "        #else:\n",
    "        #    m = re.findall(r'\\w\\w$', d)\n",
    "        #    i = float(m[0:]) + 1\n",
    "        #    d = d[:10] + '_' + str(i).zfill(2)\n",
    "        #os.mkdir(d)'''\n",
    "        shutil.rmtree(d)\n",
    "        #os.rmdir(d)\n",
    "        os.mkdir(d)\n",
    "        \n",
    "create_date_dir()\n",
    "\n",
    "# This will point to where the job is being run from NOT the directory where this file lives (mnt/notebooks/scratch), when run as a Domino Job \n",
    "current_dir = os.getcwd()\n",
    "    \n",
    "## Read in service account credentials - link to whichever json file holds your credentials\n",
    "gc = gspread.service_account(filename='/mnt/data/odt-data-profiler-069defc7abf3.json')\n",
    "\n",
    "## Spreadsheet key of your destination \n",
    "sh2 = gc.open_by_key('1gtMHAQkfufSOPb3hpThM_aZ0rwV8NG-CeVh3BY2dorQ')\n",
    "\n",
    "# Read data from worksheet\n",
    "worksheet2 = sh2.get_worksheet(0)\n",
    "list_of_lists = worksheet2.get_all_records()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "535107c1-2a2f-4a85-b57c-34df0a3f1622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'agency': 'DOB', 'dataset': 'Certificate of Occupancy', '4x4': 'pkdm-hqz6'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b698e7-b611-40fe-b788-b93560da8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_data(list_of_lists):\n",
    "    for i in range (0,len(list_of_lists)):\n",
    "        agency_name = list_of_lists[i]['agency']\n",
    "        dataset_name = list_of_lists[i]['dataset']\n",
    "        url = list_of_lists[i]['api_endpoint']\n",
    "        dataset_url = f'https://data.cityofnewyork.us/resource/{url}.json'\n",
    "        #count = list_of_lists[i]['count']\n",
    "        #limit = dataset_url+\"?$select=count(*)\n",
    "        chunk_size = 1000\n",
    "        offset = 0\n",
    "        reached_end_of_dataset = False\n",
    "        tmp_dfs = []\n",
    "        while not reached_end_of_dataset:\n",
    "            chunk_url = f'{dataset_url}?$limit={chunk_size}&$offset={offset}'\n",
    "            tmp_r = requests.get(chunk_url, auth=(\"8febnpgtxedbep4no9oqegrce\",\"36g68l45jhsdzeu08j3i44j4nxn2t65ua1gw4o0xwa9o17ownv\"), timeout=None) #pd.read_json(chunk_url)\n",
    "            tmp = pd.DataFrame(tmp_r.json())\n",
    "            tmp_dfs.append(tmp)\n",
    "            #print(chunk_url)\n",
    "    \n",
    "            if tmp.shape[0] == chunk_size:\n",
    "                if offset <= 9860000:\n",
    "                    offset += chunk_size\n",
    "                else:\n",
    "                    break\n",
    "    \n",
    "            else: # if got the last chunk, should be smaller than the chunk size \n",
    "                reached_end_of_dataset = True\n",
    "\n",
    "        out_df = pd.concat(tmp_dfs, axis=0)\n",
    "        #r = requests.get(dataset_url+f\"?$limit=500000\", auth=(\"8febnpgtxedbep4no9oqegrce\",\"36g68l45jhsdzeu08j3i44j4nxn2t65ua1gw4o0xwa9o17ownv\"), timeout=None)\n",
    "        prl = ProfileReport(out_df, title=f\"{dataset_name}_Data_Profiler\", html={\"style\": {\"full_width\": True}}, sort=None,\n",
    "            correlations=None,\n",
    "            interactions=None,\n",
    "            missing_diagrams={\n",
    "                \"bar\": False,\n",
    "                \"matrix\": True,\n",
    "                \"heatmap\": False,\n",
    "                \"dendrogram\": False,\n",
    "            })\n",
    "        out = prl.to_file(current_dir + \"/\" + todaystr + \"/\" + f\"{todaystr}_{agency_name}_{dataset_name}.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bafbaa25-84ce-44c0-859c-3cfd9e9312d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING\n",
    "\n",
    "# Function to profile each dataset\n",
    "def profile_data(list_of_lists):\n",
    "    for i in range (0,len(list_of_lists)):\n",
    "        agency_name = list_of_lists[i]['agency'] # agency field for each row - will be used in the report name\n",
    "        dataset_name = list_of_lists[i]['dataset'] # dataset name for each row - will be used in the report name\n",
    "        url = list_of_lists[i]['4x4'] # 4x4 for each row - will be used to identify the dataset and read in the data from the API endpoint\n",
    "        dataset_url = f'https://data.cityofnewyork.us/resource/{url}.json' # defining the url using the 4x4 for each row\n",
    "        chunk_size = 100000 # the chunk size is the limit that will be set for the get requests. Only 100000 rows are read at a given time. \n",
    "        offset = 0\n",
    "        reached_end_of_dataset = False\n",
    "        tmp_dfs = []\n",
    "        while not reached_end_of_dataset:\n",
    "            chunk_url = f'{dataset_url}?$limit={chunk_size}&$offset={offset}'\n",
    "            tmp_r = requests.get(chunk_url, auth=(\"8febnpgtxedbep4no9oqegrce\",\"36g68l45jhsdzeu08j3i44j4nxn2t65ua1gw4o0xwa9o17ownv\"), timeout=None)\n",
    "            tmp = pd.DataFrame(tmp_r.json())\n",
    "            tmp_dfs.append(tmp)\n",
    "            print(chunk_url)\n",
    "            \n",
    "            if (tmp.shape[0] == chunk_size): \n",
    "                if (offset < 10000000): # Offset and limit are used together to incrementally read 100000 rows at a time if we have not reached the end of the dataset. \n",
    "                    offset += chunk_size\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "            else: # if got the last chunk, should be smaller than the chunk size \n",
    "                reached_end_of_dataset = True\n",
    "\n",
    "        out_df = pd.concat(tmp_dfs, axis=0) # chunks of dataset are concatenated to get the full dataset. NOTE THAT THIS STEP FAILS FOR VERY LARGE DATASETS LARGER THAN ~ 10 MILLION ROWS.\n",
    "        prl = ProfileReport(out_df, minimal=True, show_variable_description=False, variables={ \"descriptions\": {} } , title=f\"{dataset_name}_Profile\", sort=None,\n",
    "            correlations=None,\n",
    "            interactions=None,\n",
    "            missing_diagrams=None)\n",
    "        \n",
    "        out = prl.to_file(current_dir + \"/\" + todaystr + \"/\" + f\"{todaystr}_{agency_name}_{dataset_name}.html\") # output the report to the appropriate directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66d6847a-44bf-4c95-a9c0-15ca4f33013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://data.cityofnewyork.us/resource/pkdm-hqz6.json?$limit=100000&$offset=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3afc70c90d4c3a97900ad409bba48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a396687d2eb34a798e48bfaa2df26321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39fefb3405d497ea9e5e901f43e33c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4843f7b27ad4825b773fbfd4a8258a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile_data(list_of_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "807cde6d-3de8-4ce2-b166-0f85c7bcda47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83221fc6-ec52-4573-842e-9e7392334411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/conda/bin/python'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "384cb37c-4500-4699-9e93-047d2d074fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.cityofnewyork.us/resource/j34j-vqvt.json'\n",
    "    \n",
    "chunk_size = 1000\n",
    "offset = 0\n",
    "reached_end_of_dataset = False\n",
    "\n",
    "\n",
    "tmp_dfs = []\n",
    "\n",
    "while not reached_end_of_dataset:\n",
    "    chunk_url = f'{url}?$limit={chunk_size}&$offset={offset}'\n",
    "    \n",
    "    tmp = pd.read_json(chunk_url)\n",
    "    tmp_dfs.append(tmp)\n",
    "    \n",
    "    if tmp.shape[0] == chunk_size:\n",
    "        offset += chunk_size\n",
    "        \n",
    "    else: # if got the last chunk, should be smaller than the chunk size \n",
    "        reached_end_of_dataset = True\n",
    "\n",
    "out_df = pd.concat(tmp_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95ca5aab-b303-4e64-943a-3faae26c6d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>incidentclassification</th>\n",
       "      <th>incidentborough</th>\n",
       "      <th>incidentcount</th>\n",
       "      <th>averageresponsetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009/07</td>\n",
       "      <td>All Fire/Emergency Incidents</td>\n",
       "      <td>Citywide</td>\n",
       "      <td>40850</td>\n",
       "      <td>04:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009/07</td>\n",
       "      <td>All Fire/Emergency Incidents</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10709</td>\n",
       "      <td>04:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009/07</td>\n",
       "      <td>All Fire/Emergency Incidents</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>8137</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009/07</td>\n",
       "      <td>All Fire/Emergency Incidents</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>2205</td>\n",
       "      <td>04:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009/07</td>\n",
       "      <td>All Fire/Emergency Incidents</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11505</td>\n",
       "      <td>04:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>FY 2017</td>\n",
       "      <td>Structural Fires</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>5669</td>\n",
       "      <td>04:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>FY 2017</td>\n",
       "      <td>Structural Fires</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>5829</td>\n",
       "      <td>04:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>FY 2017</td>\n",
       "      <td>Structural Fires</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>1266</td>\n",
       "      <td>04:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>FY 2017</td>\n",
       "      <td>Structural Fires</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>7949</td>\n",
       "      <td>03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>FY 2017</td>\n",
       "      <td>Structural Fires</td>\n",
       "      <td>Queens</td>\n",
       "      <td>5362</td>\n",
       "      <td>04:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4368 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yearmonth        incidentclassification incidentborough  incidentcount  \\\n",
       "0     2009/07  All Fire/Emergency Incidents        Citywide          40850   \n",
       "1     2009/07  All Fire/Emergency Incidents       Manhattan          10709   \n",
       "2     2009/07  All Fire/Emergency Incidents           Bronx           8137   \n",
       "3     2009/07  All Fire/Emergency Incidents   Staten Island           2205   \n",
       "4     2009/07  All Fire/Emergency Incidents        Brooklyn          11505   \n",
       "..        ...                           ...             ...            ...   \n",
       "363   FY 2017              Structural Fires       Manhattan           5669   \n",
       "364   FY 2017              Structural Fires           Bronx           5829   \n",
       "365   FY 2017              Structural Fires   Staten Island           1266   \n",
       "366   FY 2017              Structural Fires        Brooklyn           7949   \n",
       "367   FY 2017              Structural Fires          Queens           5362   \n",
       "\n",
       "    averageresponsetime  \n",
       "0                 04:27  \n",
       "1                 04:32  \n",
       "2                 04:37  \n",
       "3                 04:45  \n",
       "4                 04:01  \n",
       "..                  ...  \n",
       "363               04:26  \n",
       "364               04:22  \n",
       "365               04:28  \n",
       "366               03:42  \n",
       "367               04:34  \n",
       "\n",
       "[4368 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f731e8c-ce0f-4489-bf70-b8bf6e2a3444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "filename = \"data.txt\"\n",
    "n = sum(1 for line in open(filename)) - 1 #number of records in file (excludes header)\n",
    "s = 10000 #desired sample size\n",
    "skip = sorted(random.sample(range(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "df = pandas.read_csv(filename, skiprows=skip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
